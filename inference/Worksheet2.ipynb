
{"cells": [{"cell_type": "markdown", "metadata": {"hide_input": true}, "source": "# Worksheet 2: Inference with two parameters\n\nThis time, let's assume we don't know the *phase* of the sine curve, either. Our model is now\n\n$\nm(P) = 1 + 0.1 \\sin\\left(\\frac{2\\pi}{P} t + \\phi\\right)\n$\n\nwhere (as before) $m$ is the model, $P$ is the period, $t$ is time, and now $\\phi$ is a phase offset in radians."}, {"cell_type": "markdown", "metadata": {}, "source": "## 1. Import the modules we'll need"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit"}, {"cell_type": "markdown", "metadata": {}, "source": "## 2. Load the dataset\nIt's stored in the text file ``data/worksheet2.txt``. We'll load the time array ``time``, the flux array ``flux``, and the array of uncertainties ``err``:"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "time, flux, err = np.loadtxt(\"data/worksheet2.txt\").T"}, {"cell_type": "markdown", "metadata": {}, "source": "## 3. Plot the dataset\nPlot the dataset (flux versus time) to visualize what we're dealing with, and eyeball the value of the period from the plot."}, {"cell_type": "markdown", "metadata": {}, "source": "## 4. Define our model\n\nWrite a function that returns the model we are going to fit to the data. In this case, the model $m$ is a function of *two* variables, the period $P$ and phase $\\phi$, whose values we're going to try to infer.\n\n```python\ndef model(period, phase):\n    return (...)\n```"}, {"cell_type": "markdown", "metadata": {}, "source": "## 5. Grid search for the period and phase\n\nAs before, define an array of ``1,000`` periods over a range that's large enough to include the true period of the dataset. Call this array ``periods``. Also define an array of ``1,000`` phases that spans the range $[0, 2\\pi]$ and call it ``phases``. For each *pair of values*, compute the model and the chi-squared ($\\chi^2$) value of that model. Store the chi-squared in the two-dimensional array ``chisq``, where ``chisq[i, j]`` corresponds to the chi-squared of the ``ith`` period and the ``jth`` phase.\n\nAs before, time the cell by adding\n\n```python\n%%time\n```\n\nto the top of the cell. How much slower did it run (be patient!)?"}, {"cell_type": "markdown", "metadata": {}, "source": "## 6. Plot $\\chi^2$\n\nThis time $\\chi^2$ is two-dimensional, so we need to plot a heatmap. Do this by running \n\n```python\nplt.imshow(chisq, origin='lower', extent=extent)\n```\n\nwhere ``extent = (phases.min(), phases.max(), periods.min(), periods.max())``. The phases should be along the horizontal axis, and the periods along the vertical axis.\n\nIdentify the minimum in the plot and record the corresponding values of the period and phase."}, {"cell_type": "markdown", "metadata": {}, "source": "## 7. Plot the likelihood\n\nOn the same kind of 2-d heat map, plot the likelihood function as we did in the first worksheet. Zoom in on the region of highest likelihood."}, {"cell_type": "markdown", "metadata": {}, "source": "## 8. Fit a Gaussian\nAs before, let's fit a Gaussian to the likelihood so we can obtain an uncertainty on each of the parameters. The tricky bit is that our function is two-dimensional, which makes fitting it a pain (at least in the way we did it before). To keep things simple, and to introduce a concept that will be useful later on, let's collapse the likelihood plot above into two one-dimensional plots representing the likelihood of the period and of the phase, respectively, **independently** of the value of the other parameter. In other words, let's compute the projection of the two-dimensional distribution above onto each axis -- you can think of this as the \"shadow\" of the blob if I were to shine a flashlight on it, pointing toward the `x` and then the `y` axes. Each of these shadows is a Gaussian, so we can solve for the mean and standard deviation of the period and the phase separately by fitting the two 1-dimensional curves individually.\n\nThis process of collapsing is called *marginalization*, and it's super simple. To compute the *marginal likelihood* of one variable, we just *sum* over the likelihood at every value of the *other variable*. For example, the marginal likelihood of the phase is\n\n```python\nlike_phases = np.sum(likelihood, axis=0)\n```\n\nand the marginal likelihood of the period is\n\n```python\nlike_periods = np.sum(likelihood, axis=1)\n```\n\nDefine the gaussian function as we did in the previous worksheet and fit it to the marginal likelihood of each parameter to arrive at the mean and standard deviation of the period and phase. Overplot both gaussians on the marginal likelihood curves to check that you got a good fit."}, {"cell_type": "markdown", "metadata": {}, "source": "## 10. Plot our best model w/ uncertainties\nFinally, let's compute the model we defined above using the values of the period and phase we obtained, and overplot it on the data. Is it a good fit?\n\nDon't bother trying to plot the uncertainty (as we did before with ``plt.fill_between``) since in two dimensions things are a little tricker. We'll talk about that next time."}, {"cell_type": "markdown", "metadata": {}, "source": "## 11. Higher dimensions\nLooking back at how long it took to solve for the parameters of the model in the 1-d case (Worksheet 1) and the 2-d case (Worksheet 2), what can you predict about how long it would take to fit a model with 3 parameters using this method? At what point would it become effectively impossible to do this? When modeling light curves, there are usually a dozen -- or even dozens -- of variables to solve for. Is it feasible to model light curves this way? If not, think about how we might actually do inference in practice."}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 2}
